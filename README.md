# Amazon-ML-Hackathon
# ğŸ§  Memory-Efficient Multi-Modal Price Prediction Pipeline

### TF-IDF + SVD + EfficientNet-B0 + XGBoost

ğŸ“¦ **Challenge:** Amazon ML Hackathon 2025 â€“ *Smart Product Pricing*
ğŸ“Š **Goal:** Predict product prices from multimodal data (catalog text + product image)
âš¡ **Local Metric (SMAPE):** ~36.8
ğŸ§® **Frameworks:** PyTorch Â· timm Â· XGBoost Â· scikit-learn Â· Optuna

---

## ğŸš€ Overview

This repository implements a **memory-efficient, multimodal regression pipeline** to predict product prices using:

* **Text features** extracted via TF-IDF + TruncatedSVD
* **Image embeddings** from a pretrained EfficientNet-B0
* **XGBoost regression** optimized via Optuna

The focus is on:

* ğŸ”¹ Reducing RAM and GPU load
* ğŸ”¹ Maintaining strong model accuracy
* ğŸ”¹ Combining text + image modalities effectively

---
## Problem Statement

Business Objective:
E-commerce platforms must set competitive and fair prices for products listed on their marketplace. The task is to predict the price of a product given its structured catalog text and an associated image. Accurate price predictions help in pricing recommendations, auto-listing, fraud detection, and search ranking.

Task Description (ML perspective):

Input:

catalog_content â€” a text blob containing structured fields like Item Name, Unit, Value, Bullet Points, and Product Description.

image_link â€” URL or local path to product image.

Output:

A predicted price (positive float).

Evaluation:

Metric: SMAPE (Symmetric Mean Absolute Percentage Error) â€” lower is better.

Constraints:

No external price lookup (web scraping / external APIs).

Use open-source models/libraries (competition licensing constraints).

Model must generalize across categories, brands, and image quality variance.

Why SMAPE? SMAPE measures relative errors robustly when price values span orders of magnitude (many low-price items, few luxury items).

## ğŸ§© Architecture

```
Input: catalog_content, image_link, price
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse Catalog Content         â”‚
â”‚  â€¢ Item Name, Unit, Value     â”‚
â”‚  â€¢ Bullet Points & Descriptionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clean & Normalize Text        â”‚
â”‚  â€¢ Remove stopwords, symbols  â”‚
â”‚  â€¢ Combine bullet pts + desc  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TF-IDF + TruncatedSVD         â”‚
â”‚  â€¢ Brand, Unit, Features      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EfficientNet-B0               â”‚
â”‚  â€¢ Extract 1280-D embeddings  â”‚
â”‚  â€¢ Batch processing w/ GPU    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ XGBoost + Optuna              â”‚
â”‚  â€¢ SMAPE-based optimization   â”‚
â”‚  â€¢ GPU-accelerated training   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
 Output: Trained model + artifacts
```

---

## ğŸ§± Dataset

**Input Columns:**

| Column            | Description                                    |
| ----------------- | ---------------------------------------------- |
| `catalog_content` | Text block with structured product information |
| `image_link`      | URL or local path to product image             |
| `price`           | Target variable (float)                        |

**Example (simplified):**

```
Item Name: Amul Butter 500g
Unit: 500g
Value: 500
Bullet Point 1: Made from fresh cream
Product Description: Delicious, pure and healthy butter for everyday use.
Image Link: https://images.amazon.com/amul.jpg
Price: 250
```

---

## âš™ï¸ Configuration

| Parameter            | Value                           |
| -------------------- | ------------------------------- |
| Random Seed          | 42                              |
| Image Model          | EfficientNet-B0                 |
| Text Models          | TF-IDF (brand/features/unit)    |
| Dim Reduction        | TruncatedSVD (3000 + 5000 + 64) |
| ML Model             | XGBoost                         |
| Hyperparameter Tuner | Optuna (20 trials)              |
| Evaluation Metric    | SMAPE                           |
| Device               | GPU (cuda) if available         |

---

## ğŸ§  Key Components

### 1ï¸âƒ£ **Text Parsing & Cleaning**

* Extracts fields like `Item Name`, `Unit`, `Value`, and `Product Description`
* Cleans and tokenizes text (lowercasing, regex removal, stopword filtering)
* Removes unit keywords (e.g., â€œkgâ€, â€œmlâ€) from item names

### 2ï¸âƒ£ **TF-IDF + SVD Compression**

| Feature Type     | Max Features | SVD Components |
| ---------------- | ------------ | -------------- |
| Brand            | 15,000       | 3,000          |
| Product Features | 30,000       | 5,000          |
| Unit             | 128          | 64             |

Reduces sparse matrices into dense, low-memory representations.

### 3ï¸âƒ£ **Image Embedding Extraction**

* Uses pretrained `EfficientNet-B0` (from `timm`)
* Generates **1280-D global average pooled embeddings**
* Batch processing (default: 200 images per batch)
* Handles missing or broken URLs gracefully (returns zero vector)

### 4ï¸âƒ£ **Feature Fusion**

* Concatenates `[SVD-text vectors + scaled numeric value + image embeddings]`
* Results in a **dense multimodal feature matrix**

### 5ï¸âƒ£ **Model Training (Optuna + XGBoost)**

Optuna optimizes:

```python
learning_rate âˆˆ [0.01, 0.04]
n_estimators âˆˆ [3000, 4000]
max_depth âˆˆ [6, 10]
```

Training uses GPU acceleration (`tree_method="gpu_hist"`).

**Early stopping:** 100 rounds
**Validation split:** 80/20
**Metric:** SMAPE (Symmetric Mean Absolute Percentage Error)

---

## ğŸ“ˆ Results

| Model               | Data Used  | SMAPE (â†“)  |
| :------------------ | :--------- | :--------- |
| TF-IDF + SVD        | Text only  | ~44.0      |
| EfficientNet        | Image only | ~41.5      |
| Text + Image Fusion | **Both**   | **36.8 âœ…** |

---

## ğŸ’¾ Saved Artifacts

| File                          | Description                     |
| ----------------------------- | ------------------------------- |
| `xgb_mem_efficient_model.pkl` | Final XGBoost model             |
| `vectorizers_svd.pkl`         | TF-IDF + SVD transformers       |
| `num_scaler.pkl`              | Scaler for numeric features     |
| `price_scaler.pkl`            | Scaler for target normalization |
| `image_features.npy`          | Cached EfficientNet embeddings  |

Saved automatically under:

```
models_mem_efficient_pipeline/
```

---

## ğŸ”§ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

```bash
pip install pandas numpy torch timm xgboost optuna nltk scikit-learn pillow tqdm joblib requests
```

### 2ï¸âƒ£ Prepare Dataset

Place your `train.csv` in the same directory:

```csv
catalog_content,image_link,price
"Item Name: Amul Butter 500g\nUnit: 500g\nValue: 500\nProduct Description: Fresh cream butter",https://...,250
```

### 3ï¸âƒ£ Run the Pipeline

```bash
python train_mem_efficient_pipeline.py
```

### 4ï¸âƒ£ Output

```
âœ… Using device: cuda
ğŸ”¹ Applying SVD (memory-efficient)...
Extracting Image Features in Batches: 100%
âœ… Final combined feature shape: (N, ~9400)
âœ… Best Params: {...}
âœ… Best SMAPE: 36.8
âœ… Model, SVD transformers, scalers & image features saved successfully!
```

---

## ğŸ§© Custom Functions

| Function                  | Purpose                                         |
| ------------------------- | ----------------------------------------------- |
| `parse_catalog_content()` | Parses structured text fields                   |
| `clean_text()`            | Token cleaning & normalization                  |
| `extract_img_features()`  | Extracts image embeddings (with error handling) |
| `smape()`                 | Custom evaluation metric                        |
| `objective()`             | Optuna trial function                           |

---

## ğŸ§® Performance Optimizations

* **SVD compression** drastically reduces TF-IDF memory usage
* **Batch image embedding extraction** prevents CUDA OOM
* **GPU-based XGBoost** for fast tree building
* **Optuna** automatically tunes hyperparameters efficiently
* **Log-transform + StandardScaler** improves regression stability

---

## ğŸ”® Future Scope

* Incorporate **CLIP** for unified image-text embedding
* Add **pseudo-labeling** for unlabeled products
* Explore **LightGBM + XGBoost stacking**
* Apply **quantization or pruning** for deployment efficiency

---

## ğŸ‘¨â€ğŸ’» Author

**Naman Agrawal**
IIT Bhubaneswar Â· Mechanical Engineering
ğŸ“§ [[your.email@example.com](mailto:your.email@example.com)]
ğŸ”— [github.com/yourusername]

---

Would you like me to make an additional **section with command examples for inference/prediction** (e.g., loading `xgb_mem_efficient_model.pkl` to predict on test.csv)?
That would complete this README for real submission use.
