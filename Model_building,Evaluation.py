# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVevkEsDt1wIJcI-QQ4939XJngrd3va4
"""

# evaluation metrics and model building

# TRAIN/TEST SPLIT

X_train, X_valid, y_train, y_valid = train_test_split(X_final, y, test_size=0.2, random_state=SEED)

# SMAPE METRIC

def smape(y_true, y_pred):
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))

# OPTUNA OBJECTIVE FUNCTION
def objective(trial):
    params = {
        "objective": "reg:squarederror",
        "eval_metric": "mae",
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.04),
        "n_estimators": trial.suggest_int("n_estimators", 3000, 4000),
        "max_depth": trial.suggest_int("max_depth", 6, 10),
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "min_child_weight": 3,
        "random_state": SEED,
        "n_jobs": -1,
        "tree_method": "gpu_hist" if torch.cuda.is_available() else "hist"
    }

    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],
              verbose=False, early_stopping_rounds=100)

    preds_scaled = model.predict(X_valid)
    preds_log = scaler_price.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()
    y_valid_log = scaler_price.inverse_transform(y_valid.reshape(-1, 1)).ravel()

    preds = np.expm1(preds_log)
    y_true = np.expm1(y_valid_log)

    return smape(y_true, preds)

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=20, show_progress_bar=True)




#  MODEL TRAINING
best_params = study.best_params
final_model = xgb.XGBRegressor(**best_params)
final_model.fit(X_final, y)

